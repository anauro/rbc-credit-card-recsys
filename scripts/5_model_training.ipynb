{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2154e55b-dd2c-48f8-8629-0a91af0355ba",
   "metadata": {},
   "source": [
    "## MODEL TRAINING\n",
    "\n",
    "Train model with LightGBM and identify performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7356722-f053-497f-b5e6-d94a5dd00e44",
   "metadata": {},
   "source": [
    "##### Timing \n",
    "We want to time how long these programs take to run. We are interested both in real time and CPU time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e69ca6-281d-45ec-8122-5648fe0aa6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "start_time = time.time()\n",
    "start_cpu_time = time.process_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ffbcd-d515-403a-b198-99cf356bf3a4",
   "metadata": {},
   "source": [
    "#### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80814562-cf38-4326-a7a0-137f722602f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType, StringType, FloatType\n",
    "from pyspark.sql.functions import collect_list, regexp_replace, lower\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "from functools import reduce\n",
    "\n",
    "import datetime \n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5fe20-113d-4762-b744-b0001b4573f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning Libraries \n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve, classification_report, roc_auc_score, average_precision_score\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031422e6-e72e-4401-9ab4-84fedae5a686",
   "metadata": {},
   "source": [
    "#### Import Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e69c11-31b3-41f2-bbd6-f49f3c81f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = spark.read.load(\"/anaurosevic/cdn0_cards_affinity/model_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a605a-b1bb-46e3-8a70-3640b151cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = md.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae800f6-fa14-47d5-8ad1-dd9c258df59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb0d760-f324-4982-b353-6f4828a3bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.memory_usage(deep=True).sum()/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a898f-6d94-43d1-aac6-fddb0321683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_prevalence = model_data.groupby('product_code').size().reset_index(name='counts').sort_values('counts',ascending = False)\n",
    "cc_prevalence['prop'] = round(cc_prevalence['counts']/cc_prevalence['counts'].sum()*100,1)\n",
    "cc_prevalence #Class imbalance - need to deal with this ~ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9309793a-e8e3-4eae-82b9-43a4b7577174",
   "metadata": {},
   "source": [
    "#### Scale Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc2f10-8b85-45b0-a4ff-1b003f8cf575",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = list(model_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef50d76-fc3a-40ca-b4e6-60cfc4e15aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = [\"device_\",\"province_\",\"sess_channel_\"]\n",
    "filtered_list = [item for item in all_vars if item.startswith(tuple(prefixes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04408975-3751-489c-be09-cfbc587ee747",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = list(model_data.columns)\n",
    "\n",
    "#Manually specify non-cont vars [majority are continuous] \n",
    "non_cont_vars = ['user_pseudo_id','product_code','postal_code'] + filtered_list #Primary keys + non-cont\n",
    "\n",
    "cont_vars = list(set(all_vars)-set(non_cont_vars))\n",
    "cont_vars.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bfb434-995b-4cd3-a8e1-0d8383a29f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "scaled = scale.fit_transform(model_data[cont_vars])\n",
    "\n",
    "scaled_df = pd.DataFrame(scaled)\n",
    "scaled_df.columns = cont_vars\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d02eaa-0ad9-4728-9072-e4f74bd437ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_scaled = pd.concat([model_data.drop(columns = cont_vars, axis=1), scaled_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850719a-c2bb-444c-858f-8eb8e81e2a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9f013-02a4-4c52-8408-9240deb0209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of user_pseudo_id :) \n",
    "md_final = model_data_scaled.drop('user_pseudo_id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bafc54-ca54-4120-8ceb-348c58399337",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(md_final.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777b4059-398a-46c5-a269-7097e53dd169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save for Erick\n",
    "sampled_df = md_final.sample(n=1000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5402d7-42a8-49bb-857f-5942af538b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d634fac-203d-4a08-9a16-8bb1a3d342be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save \n",
    "sampled_df.to_csv('sample_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e87c17d-7250-4030-a1bd-1126b84cf016",
   "metadata": {},
   "source": [
    "#### Split X & Y and Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c709a4-4075-4f8e-b8a9-a58c5385c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = md_final.drop(['product_code','postal_code'], axis=1)\n",
    "y = md_final['product_code'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c2ae7-de52-44f4-8b6d-49cf0b0b8da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.memory_usage(deep=True).sum()/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ad1de-62a7-46c1-9d5d-d1913f5a0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee06516-33db-4008-9fae-fd3480899095",
   "metadata": {},
   "source": [
    "#### Class Weights for Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f3bd75-758f-4efd-92ed-e5402a65e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example data\n",
    "classes = np.unique(y_train)  # Unique class labels\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "\n",
    "#Create a mapping from class labels to class weights\n",
    "class_weights_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "#Map labels in y_train to their corresponding weights\n",
    "sample_weights = np.array([class_weights_dict[label] for label in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cf315d-a1f5-4a46-873b-6cc4d056702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1695cd08-794a-4ef5-832b-f427965dd7ac",
   "metadata": {},
   "source": [
    "#### Define Hyperparameter Tuning Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867b912e-f94d-463f-b151-efb06f6f8be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective = 'multi:softprob', #Multicategory classification curve\n",
    "    eval_metric = 'mlogloss', #Precision-recall curve is best for imbalanced data\n",
    "    use_label_encoder = False,\n",
    "    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db37b8-f25d-4444-9461-dee79bf6191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = lgb.LGBMClassifier(\n",
    "    objective = 'multiclass',\n",
    "    random_state = 42, \n",
    "   # class_weight = class_weights_dict, #To try to address imbalance \n",
    "    is_unbalance = True,\n",
    "    verbosity = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c53d2-235a-4749-bdcc-1eaf6131e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Broad params\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1], # step size shrinkage\n",
    "    \"n_estimators\": [100, 150, 200], # number of trees\n",
    "    \"num_leaves\": [20, 30, 40]\n",
    "}\n",
    "#Without offers: {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 30}\n",
    "#With offers: {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbf3929-6729-430d-a911-35decfe8e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Double click\n",
    "# param_grid_dc = {\n",
    "#     \"learning_rate\": [0.025, 0.05, 0.075], \n",
    "#     \"n_estimators\": [75, 100, 125], \n",
    "#     \"num_leaves\": [15, 20, 25]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8540fa4-949a-438d-908e-589fe7ad4ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator = lgbm_model,\n",
    "    param_grid = param_grid,\n",
    "    scoring = \"accuracy\",\n",
    "    verbose = 2,\n",
    "    cv = 5,\n",
    "    n_jobs = 2 #Keep it at 2 for memory reasons :D \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfa3290-3b3f-4434-aa5a-a85544c9f4af",
   "metadata": {},
   "source": [
    "#### Perform Grid Search (Find Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fa2954-3eac-4aaf-abaf-f236ff6a0d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_start_time = time.time()\n",
    "print(training_start_time)\n",
    "\n",
    "grid_search.fit(X_train, y_train) \n",
    "\n",
    "training_end_time = time.time()\n",
    "print(training_end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb66be7-7831-44ab-b977-35b157019fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model training took\", round((training_end_time-training_start_time)/60),\"minutes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7928b6-7eef-4b37-bbd2-80e496bb1222",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7fd0e2-b705-4129-a1d5-abc9ba2612a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06016cd2-18c4-4471-8821-25fd0f7d4984",
   "metadata": {},
   "source": [
    "#### Save Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640aaa58-116d-4426-b1c9-6f213a4d1895",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_pd = pd.DataFrame.from_dict(best_params, orient='index').T\n",
    "best_params_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b2265-ad7f-42c4-9e8b-b4bea563c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_spark = spark.createDataFrame(best_params_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9f378-42e9-4dec-80f2-5456d0a420ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_spark.write.mode(\"overwrite\").parquet(\"/anaurosevic/cdn0_cards_affinity/best_params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0c5d74-2439-479f-8bf1-aff784806aec",
   "metadata": {},
   "source": [
    "#### Load Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10f197b-5d8e-44cd-b1dc-982a2a8f47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = spark.read.load(\"/anaurosevic/cdn0_cards_affinity/best_params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9651c7b9-7ba8-4d30-980b-7e135a5269d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3c6d32-064e-40d5-b227-8d19e41620d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_dict = best_params.toPandas().iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca3df3b-51ce-49d5-bc1f-2ee7f827708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert from float to integer\n",
    "best_params_dict['n_estimators'] = int(best_params_dict['n_estimators'])\n",
    "best_params_dict['num_leaves'] = int(best_params_dict['num_leaves'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7088c02-5783-4cd5-bc02-067173d80849",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc6db4-d12d-48f4-a3da-e9f8dfe34e27",
   "metadata": {},
   "source": [
    "#### Refit Using Best Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5a5e7-b9f3-4388-a07c-1134894fc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = lgb.LGBMClassifier(\n",
    "    objective = 'multiclass',\n",
    "    #class_weight = class_weights_dict, #To try to address imbalance - tested, but performance is worse \n",
    "    random_state = 42, \n",
    "    verbosity = 0,\n",
    "    **best_params_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612da688-a5dd-445c-b8a8-f04014373343",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c17e11-25e9-4eb1-96d7-c1116ed35a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the trained model \n",
    "with open(\"lgbm_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97131cc-1569-4b4d-a301-f17e559d5ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the model \n",
    "with open(\"lgbm_model.pkl\", \"rb\") as file:\n",
    "    loaded_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951dfc66-b3c6-47a8-84fb-e20f1d48aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3021474-34fd-48a7-8585-2d91815de69a",
   "metadata": {},
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cacefb-7b8d-42df-bbd0-a2e6e0e1e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = loaded_model.predict_proba(X_test)\n",
    "print(pred_probs.shape)\n",
    "#The result is a probability distribution across all of the classes (14 CCs)\n",
    "pred_probs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2d10ce-a363-43f0-8387-bfdba2b7e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do we know what the order is? Should be the same as y_train \n",
    "class_labels = np.sort(np.unique(y_train))\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20724a7a-4e70-436d-b4e3-3dd957762651",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_df = pd.DataFrame(pred_probs)\n",
    "pred_probs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f155bece-fbcb-46e4-a86f-b1e2bc26512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns \n",
    "pred_probs_df.columns = class_labels\n",
    "pred_probs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb6deff-fad3-432a-9984-7b8d9c8b7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_df['predicted_class'] = pred_probs_df.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a63a2-9a32-45dc-a78a-9693e079bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_comparison = pd.DataFrame()\n",
    "y_comparison['actual'] = y_test\n",
    "y_comparison['predicted'] = pred_probs_df['predicted_class'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805c0ac7-f9be-4a7d-9a3f-2ec82384510b",
   "metadata": {},
   "source": [
    "#### Function\n",
    "Let's create a function so that we can easily swap train/test and complete/subset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7185f9fb-8126-41cd-a7fc-ae3c91f3de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(X_data, Y_data, model_type): \n",
    "\n",
    "    #Prepare features\n",
    "    #Format features as a DMatrix because best_model.predict only handles this \n",
    "    #X_dmatrix = xgb.DMatrix(X_data) #For XGBoost only\n",
    "\n",
    "    #Predict class probabilities\n",
    "    #The result is a probability distribution across all of the classes (14 CCs)\n",
    "    if (model_type=='complete'):\n",
    "        #XGBoost\n",
    "        #pred_probs = best_model.predict(X_dmatrix) \n",
    "        #LGBM \n",
    "        pred_probs = loaded_model.predict_proba(X_data)\n",
    "        \n",
    "    elif (model_type=='subset'):\n",
    "        #XGBoost\n",
    "        #pred_probs = best_model_subset.predict(X_dmatrix)\n",
    "        #LGBM \n",
    "        pred_probs = loaded_model.predict_proba(X_data)\n",
    "    \n",
    "    #Identify class labels \n",
    "    #How do we know what the order is? Should be the same as y_train \n",
    "    class_labels = np.sort(np.unique(Y_data))\n",
    "\n",
    "    #Create DF \n",
    "    pred_probs_df = pd.DataFrame(pred_probs)\n",
    "\n",
    "    #Rename columns \n",
    "    pred_probs_df.columns = class_labels\n",
    "\n",
    "    #Identify top predicted card (max probability)\n",
    "    pred_probs_df['predicted_class'] = pred_probs_df.idxmax(axis=1)\n",
    "\n",
    "    #Also identify top 3 predicted cards \n",
    "    top_3_columns = pred_probs_df.drop('predicted_class',axis=1).apply(lambda x: x.sort_values(ascending=False).head(3).index.to_list(), axis=1)\n",
    "    pred_probs_df['top_3_predicted'] = top_3_columns.to_numpy()\n",
    "\n",
    "    #Final summary \n",
    "    y_comparison = pd.DataFrame()\n",
    "    y_comparison['actual'] = Y_data\n",
    "    y_comparison['predicted'] = pred_probs_df['predicted_class'].to_numpy()\n",
    "    y_comparison['top_3'] = pred_probs_df['top_3_predicted'].to_numpy()\n",
    "\n",
    "    return y_comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f75dd-e9b0-4159-80a5-c9c6edfa4946",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_comparison_test = predictions(X_test, y_test,\"complete\")\n",
    "y_comparison_train = predictions(X_train, y_train,\"complete\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d835d-8842-4f76-b316-fba71203790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_comparison_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dc85c8-46c7-48a9-9bc9-679c76a929f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_counts = y_comparison_test.groupby('actual').size().reset_index().rename(columns={'actual':'product_code',0:'actual_counts'})\n",
    "predicted_counts = y_comparison_test.groupby('predicted').size().reset_index().rename(columns={'predicted':'product_code',0:'predicted_counts'})\n",
    "\n",
    "count_comparison = actual_counts.merge(predicted_counts, on='product_code').sort_values(by=['actual_counts'], ascending=False)\n",
    "count_comparison['diff'] = (count_comparison['predicted_counts']-count_comparison['actual_counts'])/count_comparison['actual_counts']*100\n",
    "\n",
    "count_comparison['diff']=count_comparison['diff'].round(0)\n",
    "\n",
    "count_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467daaac-3114-4449-a963-d086cd974694",
   "metadata": {},
   "source": [
    "#### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2719be2-a754-4379-bfc8-2fd0e5d31fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report - Test:\")\n",
    "print(classification_report(y_comparison_test['actual'], y_comparison_test['predicted']))\n",
    "#Accuracy of 0.54 is not too hot\n",
    "#MC4 (Westjet) performance is great: \n",
    "#i.e., we are really good at predicting when a prospect might choose a Westjet card "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34876154-f341-4939-a081-f88a69011b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report - Train:\")\n",
    "print(classification_report(y_comparison_train['actual'], y_comparison_train['predicted']))\n",
    "#Training classification to monitor overfitting!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f70bac0-ae2e-433f-bd2d-c2c07189ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of instances where correct!\n",
    "print(\"Correct card is in top 3 in the test set\",round(y_comparison_test.apply(lambda row: row['actual'] in row['top_3'], axis=1).sum()/len(y_comparison_test)*100,2),\"% of the time!\")\n",
    "print(\"Correct card is in top 3 in the train set\",round(y_comparison_train.apply(lambda row: row['actual'] in row['top_3'], axis=1).sum()/len(y_comparison_train)*100,2),\"% of the time!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e24acc6-3332-45bf-a402-69dbd40bc61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({'Score': loaded_model.booster_.feature_importance(), 'Feature': X_test.columns}).sort_values(\"Score\",ascending=False).head(10)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1844d5-990e-4d8d-9976-e7c8ed96b8fc",
   "metadata": {},
   "source": [
    "--- END PROGRAM ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267e5e3a-9256-44e5-bd34-8c0d8e9c4c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Timing summary\n",
    "end_time = time.time()\n",
    "end_cpu_time = time.process_time()\n",
    "\n",
    "real_time_elapsed = end_time - start_time\n",
    "cpu_time_elapsed = end_cpu_time - start_cpu_time\n",
    "\n",
    "print(f\"Real time: {real_time_elapsed:.2f} seconds\")\n",
    "print(f\"CPU time: {cpu_time_elapsed:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
